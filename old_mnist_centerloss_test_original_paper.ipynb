{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('Data/digit-recognizer/train.csv').astype(np.float32)\n",
    "mnist_test = pd.read_csv('Data/digit-recognizer/test.csv').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mnist_train[['label']][:30000]\n",
    "x_train = mnist_train[['pixel' + str(idx) for idx in range(784)]][:30000]\n",
    "\n",
    "y_dev = mnist_train[['label']][30000:42000]\n",
    "x_dev = mnist_train[['pixel' + str(idx) for idx in range(784)]][30000:42000]\n",
    "\n",
    "x_test = mnist_test[['pixel' + str(idx) for idx in range(784)]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: float32(784)\n",
      "memory usage: 83.7 MB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000, 1) (12000, 784) (12000, 1) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_dev = scaler.transform(x_dev)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_dev.shape, y_dev.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def DNN_BN(x, weights, beta, scale, activation_function = None):\n",
    "    wx = tf.matmul(x, weights)\n",
    "    mean, var = tf.nn.moments(x=wx, axes=[0])\n",
    "    bn = tf.nn.batch_normalization(wx, mean, var, beta, scale, EPSILON)\n",
    "    if not activation_function:\n",
    "        return bn\n",
    "    else:\n",
    "        return activation_function(bn)\n",
    "    \n",
    "def DNN(x, weights, biases, activation_function = None):\n",
    "    wx = tf.matmul(x, weights)\n",
    "    score = wx + biases\n",
    "    if not activation_function:\n",
    "        return score\n",
    "    else:\n",
    "        return activation_function(score)\n",
    "    \n",
    "def weight_variable(shape):\n",
    "    initial = tf.random.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def scale_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "      return tf.nn.conv2d(input=x, filters=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool2d(input=x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "def get_center_loss(features, labels):\n",
    "    with tf.compat.v1.variable_scope('center', reuse=True):\n",
    "        centers = tf.compat.v1.get_variable('centers')\n",
    "    \n",
    "    len_features = features.get_shape()[1]\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "\n",
    "    loss = tf.reduce_sum(input_tensor=(features - centers_batch) ** 2, axis=[1])\n",
    " \n",
    "    return loss\n",
    "\n",
    "def update_centers(features, labels, alpha):\n",
    "    with tf.compat.v1.variable_scope('center', reuse=True):\n",
    "        centers = tf.compat.v1.get_variable('centers')\n",
    "    \n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "    \n",
    "    diff = centers_batch - features\n",
    "\n",
    "    unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)\n",
    "    appear_times = tf.gather(unique_count, unique_idx)\n",
    "    appear_times = tf.reshape(appear_times, [-1, 1])\n",
    "\n",
    "    diff = diff / tf.cast((1 + appear_times), tf.float32)\n",
    "    diff = alpha * diff\n",
    "\n",
    "    centers = tf.compat.v1.scatter_sub(centers,labels, diff)\n",
    "    \n",
    "    return centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS, Softmax_loss, Center_loss [107.79014, array([2.5941334 , 0.5708584 , 3.5006802 , ..., 4.659817  , 0.43560472,\n",
      "       1.9124224 ], dtype=float32), 1034.1765]\n",
      "ACC@TRAIN: 0.104\n",
      "ACC@DEV: 0.09133333\n",
      "LOSS, Softmax_loss, Center_loss [76.74749, array([0.17514414, 0.00534059, 0.12958196, ..., 1.6332753 , 1.24791   ,\n",
      "       0.36571258], dtype=float32), 760.2356]\n",
      "ACC@TRAIN: 0.78833336\n",
      "ACC@DEV: 0.7765833\n",
      "LOSS, Softmax_loss, Center_loss [60.708534, array([0.11759663, 0.00240727, 0.08563621, ..., 0.7809577 , 1.5245128 ,\n",
      "       0.09837157], dtype=float32), 601.8905]\n",
      "ACC@TRAIN: 0.8494\n",
      "ACC@DEV: 0.84575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xs = tf.compat.v1.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.compat.v1.placeholder(tf.int64, [None, 1])\n",
    "\n",
    "ys_one_hot = tf.one_hot(ys, 10)\n",
    "keep_prob = tf.compat.v1.placeholder(tf.float32)\n",
    "\n",
    "with tf.compat.v1.variable_scope('center', reuse=tf.compat.v1.AUTO_REUSE):\n",
    "    centers = tf.compat.v1.get_variable('centers', [10, 1024], dtype=tf.float32,\\\n",
    "                                        initializer=tf.compat.v1.constant_initializer(0), trainable=False)\n",
    "#------CNN1-------#\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(xs, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#-------CNN2-------#\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#-------DNN------#\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "s_fc1 = scale_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "#h_fc1 = DNN(h_pool2_flat, W_fc1, b_fc1, tf.nn.relu)\n",
    "h_fc1 = DNN_BN(h_pool2_flat, W_fc1, b_fc1, 1, activation_function = None)\n",
    "\n",
    "center_loss = get_center_loss(h_fc1, ys)\n",
    "\n",
    "update_centers = update_centers(h_fc1, ys, 0.5)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, 1 - (keep_prob))\n",
    "\n",
    "#-------DNN2-----#\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#----------------#\n",
    "softmax_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.stop_gradient(ys_one_hot), logits=y_conv)\n",
    "\n",
    "loss = tf.reduce_mean(input_tensor=softmax_loss + 0.1 * center_loss) \n",
    "\n",
    "train_op = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "result = tf.argmax(input=y_conv,axis=1)\n",
    "\n",
    "ground_truth = tf.reshape(ys, [-1])\n",
    "\n",
    "correct_prediction = tf.equal(result, ground_truth)\n",
    "\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(3):\n",
    "        print('LOSS, Softmax_loss, Center_loss', sess.run([loss, softmax_loss, tf.reduce_mean(center_loss)], feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0}))\n",
    "        print('ACC@TRAIN:', sess.run(accuracy, feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0}))\n",
    "        print('ACC@DEV:', sess.run(accuracy, feed_dict = {xs: x_dev, ys: y_dev.values, keep_prob:1.0}))\n",
    "        j = 0  \n",
    "        while j < 30000:       \n",
    "            _, cen = sess.run([train_op, update_centers], feed_dict = {xs: x_train[j:j+1000], ys: y_train[j:j+1000].values, keep_prob:1.0})\n",
    "            j += 1000  \n",
    "            \n",
    "    pd.DataFrame({\"ImageId\": range(1, len(x_test) + 1), \"Label\": sess.run(result, feed_dict = {xs: x_test, keep_prob:1.0})}).to_csv('Data/digit-recognizer/CNN.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_lazy_read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2e6f5ff32858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36mscatter_sub\u001b[0;34m(ref, indices, updates, use_locking, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m     return gen_state_ops.scatter_sub(ref, indices, updates,\n\u001b[1;32m    534\u001b[0m                                      use_locking=use_locking, name=name)\n\u001b[0;32m--> 535\u001b[0;31m   return ref._lazy_read(gen_resource_variable_ops.resource_scatter_sub(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    536\u001b[0m       \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       name=name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_lazy_read'"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "indices = tf.constant([[4], [3], [1], [7]])\n",
    "updates = tf.constant([9, 10, 11, 12])\n",
    "tensor = tf.ones([8], dtype=tf.int32)\n",
    "tensor = tf.compat.v1.scatter_sub(tensor,indices, updates)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
